# TIGAS - Trained Image Generation Authenticity Score

**A novel, differentiable metric for assessing the realism and authenticity of generated images.**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ¯ Overview

**TIGAS** is a state-of-the-art deep learning metric designed to evaluate the authenticity and realism of images, particularly for assessing generative models (GANs, Diffusion Models, etc.). Unlike existing metrics that focus on specific aspects, TIGAS combines multiple complementary analysis approaches:

- **Perceptual Analysis**: Multi-scale deep features for semantic understanding
- **Spectral Coherence**: Frequency domain analysis to detect GAN artifacts
- **Statistical Consistency**: Comparison with natural image statistics
- **Multi-Modal Fusion**: Attention-based integration of different signals

### Key Features

âœ… **Fully Differentiable** - Can be used as a loss function for training generative models
âœ… **Comprehensive** - Combines perceptual, spectral, and statistical analysis
âœ… **Easy to Use** - Simple API: `score = tigas(image)`
âœ… **Modular Design** - Clean, extensible architecture following best practices
âœ… **Research-Ready** - Includes training pipeline, evaluation tools, and visualization
âœ… **Production-Ready** - Optimized with mixed precision, gradient accumulation, etc.

---

## ğŸ“Š TIGAS Metric Innovation

### What Makes TIGAS Different?

| Metric | Perceptual | Spectral | Statistical | Differentiable | Single Image |
|--------|-----------|----------|-------------|----------------|--------------|
| **TIGAS** | âœ… | âœ… | âœ… | âœ… | âœ… |
| LPIPS | âœ… | âŒ | âŒ | âœ… | âŒ (needs reference) |
| FID | âŒ | âŒ | âœ… | âŒ | âŒ (distribution) |
| SSIM | âŒ | âŒ | âŒ | âœ… | âŒ (needs reference) |
| IS | âŒ | âŒ | âŒ | âŒ | âŒ (distribution) |

### Architecture Highlights

```
Input Image â†’ Multi-Branch Analysis â†’ Attention Fusion â†’ TIGAS Score [0, 1]
                      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“             â†“             â†“
  Perceptual    Spectral      Statistical
   Features      Analysis     Consistency
   (4 scales)  (FFT/DCT)    (Moments)
        â†“             â†“             â†“
        â””â”€â”€â”€â”€â”€â†’ Cross-Attention â†â”€â”€â”€â”˜
                      â†“
              Adaptive Fusion
                      â†“
              Score: 1.0 = Real
                     0.0 = Fake
```

---

## ğŸš€ Installation

### From Source (Recommended for Development)

```bash
# Clone repository
git clone https://github.com/H1merka/TIGAS.git
cd TIGAS

# Install in editable mode
pip install -e .

# Or install with all optional dependencies
pip install -e ".[dev,vis,training]"
```

### Using pip (After Publishing)

```bash
pip install tigas-metric
```

### Requirements

- Python â‰¥ 3.8
- PyTorch â‰¥ 1.12
- CUDA (optional, for GPU acceleration)

---

## ğŸ“– Quick Start

### Basic Usage

```python
from tigas import TIGAS

# Initialize TIGAS (with pretrained model)
tigas = TIGAS(checkpoint_path='checkpoints/best_model.pt')

# Evaluate single image
score = tigas('path/to/image.jpg')
print(f"TIGAS Score: {score:.3f}")
# Output: TIGAS Score: 0.856  (likely real)

# Evaluate directory
scores = tigas.compute_directory('path/to/images/')
print(f"Mean score: {scores.mean():.3f}")
```

### Command-Line Interface

```bash
# Evaluate single image
nair path/to/image.jpg --checkpoint checkpoints/best_model.pt

# Evaluate directory with statistics
nair --image_dir path/to/images/ --checkpoint model.pt --plot

# Output:
# TIGAS Score: 0.923
# Assessment: Likely REAL/Natural
```

### PyTorch Integration

```python
import torch
from tigas import TIGAS

# Initialize
tigas = TIGAS(checkpoint_path='model.pt', device='cuda')

# Batch processing
images = torch.randn(16, 3, 256, 256).cuda()
scores = tigas(images)  # [16, 1]

# Use as differentiable loss
loss = 1.0 - nair(generated_images).mean()
loss.backward()
```

---

## ğŸ‹ï¸ Training Your Own Model

### 1. Prepare Dataset

Organize your data:

```
data/
â”œâ”€â”€ real/
â”‚   â”œâ”€â”€ img_001.jpg
â”‚   â”œâ”€â”€ img_002.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ fake/
    â”œâ”€â”€ gan_001.jpg
    â”œâ”€â”€ diffusion_001.jpg
    â””â”€â”€ ...
```

### 2. Configure Training

Edit `configs/training_config.yaml` or use defaults:

```yaml
model:
  img_size: 256
  base_channels: 32
  feature_dim: 256

training:
  num_epochs: 100
  batch_size: 32
  learning_rate: 0.0001

data:
  train_split: 0.8
  augment_level: medium
```

### 3. Start Training

```bash
# Using script
python scripts/train.py \
    --data_root data/ \
    --config configs/training_config.yaml \
    --output_dir checkpoints/

# Or using Python API
from tigas.training import TIGASTrainer
from tigas.models import create_tigas_model
from tigas.data import create_dataloaders

# Create components
model = create_tigas_model(img_size=256)
dataloaders = create_dataloaders('data/', batch_size=32)

# Train
trainer = TIGASTrainer(tigas_model, dataloaders['train'], dataloaders['val'])
trainer.train(num_epochs=100)
```

### 4. Monitor Training

```bash
# TensorBoard
tensorboard --logdir checkpoints/logs
```

---

## ğŸ”¬ Advanced Usage

### Custom Loss Function for GANs

```python
from tigas import TIGAS

# Initialize TIGAS
tigas = TIGAS(checkpoint_path='model.pt')

# In your GAN training loop
def generator_loss(fake_images):
    # Standard GAN loss
    gan_loss = adversarial_loss(fake_images)

    # TIGAS realism loss (higher is better)
    tigas_scores = tigas(fake_images)
    realism_loss = -tigas_scores.mean()  # Maximize score

    # Combined loss
    total_loss = gan_loss + 0.1 * realism_loss
    return total_loss
```

### Feature Extraction

```python
# Get intermediate features for analysis
outputs = tigas(images, return_features=True)

score = outputs['score']  # Final TIGAS score
features = outputs['features']  # Dict of intermediate features

# Available features:
# - 'perceptual': Multi-scale perceptual features
# - 'spectral': Frequency domain features
# - 'statistical': Statistical consistency features
# - 'fused': Final fused representation
```

### Batch Evaluation with Custom Metrics

```python
from tigas.metrics import TIGASMetric

metric = TIGASMetric(model, use_model=True)

# Compute with component breakdown
results = metric(images, return_components=True)

print(f"Overall score: {results['score'].mean():.3f}")
print(f"Spectral score: {results['spectral_score'].mean():.3f}")
print(f"Statistical score: {results['statistical_score'].mean():.3f}")
```

---

## ğŸ“ Project Structure

```
TIGAS/
â”œâ”€â”€ tigas/                          # Main package
â”‚   â”œâ”€â”€ models/                    # Neural network models
â”‚   â”‚   â”œâ”€â”€ tigas_model.py         # Main TIGAS model
â”‚   â”‚   â”œâ”€â”€ feature_extractors.py # Multi-scale, spectral, statistical
â”‚   â”‚   â”œâ”€â”€ attention.py          # Cross-modal attention
â”‚   â”‚   â””â”€â”€ layers.py             # Custom layers
â”‚   â”œâ”€â”€ metrics/                   # Metric computation
â”‚   â”‚   â”œâ”€â”€ tigas_metric.py        # Main metric class
â”‚   â”‚   â””â”€â”€ components.py         # Individual metric components
â”‚   â”œâ”€â”€ data/                      # Data handling
â”‚   â”‚   â”œâ”€â”€ dataset.py            # Dataset classes
â”‚   â”‚   â”œâ”€â”€ transforms.py         # Augmentations
â”‚   â”‚   â””â”€â”€ loaders.py            # Data loaders
â”‚   â”œâ”€â”€ training/                  # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ trainer.py            # Main trainer
â”‚   â”‚   â”œâ”€â”€ losses.py             # Loss functions
â”‚   â”‚   â””â”€â”€ optimizers.py         # Optimizer configs
â”‚   â”œâ”€â”€ utils/                     # Utilities
â”‚   â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â”‚   â””â”€â”€ visualization.py      # Plotting and visualization
â”‚   â””â”€â”€ api.py                     # Public API
â”œâ”€â”€ scripts/                       # Executable scripts
â”‚   â”œâ”€â”€ train.py                  # Training script
â”‚   â””â”€â”€ evaluate.py               # Evaluation script
â”œâ”€â”€ configs/                       # Configuration files
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ training_config.yaml
â”œâ”€â”€ tests/                         # Unit tests
â”œâ”€â”€ setup.py                       # Package installation
â”œâ”€â”€ requirements.txt               # Dependencies
â””â”€â”€ README.md                      # This file
```

---

## ğŸ“ Technical Details

### Model Architecture

**TIGAS Model** consists of:

1. **Multi-Scale Feature Extractor**
   - Custom CNN backbone (EfficientNet-inspired)
   - 4-scale pyramid: {1/2, 1/4, 1/8, 1/16}
   - Gated residual blocks with CBAM attention

2. **Spectral Analyzer**
   - 2D FFT/DCT for frequency analysis
   - Radial profile computation
   - Detects checkerboard and spectral artifacts

3. **Statistical Moment Estimator**
   - Computes 5 moments: mean, variance, skewness, kurtosis, entropy
   - Learnable prototypes of natural image statistics
   - Multi-scale local statistics

4. **Cross-Modal Fusion**
   - Cross-attention between modalities
   - Adaptive feature weighting
   - Self-attention refinement

5. **Regression Head**
   - 3-layer MLP with dropout
   - Sigmoid activation â†’ [0, 1]
   - Auxiliary binary classification head

### Training Methodology

- **Loss Function**: Combined regression + classification + ranking
- **Optimizer**: AdamW with warmup and cosine annealing
- **Augmentation**: Heavy augmentation to prevent overfitting
- **Regularization**: Weight decay, dropout, gradient clipping
- **Mixed Precision**: Automatic mixed precision (AMP) for efficiency
- **Early Stopping**: Validation-based with patience

### Performance Optimizations

- âœ… Mixed precision training (FP16)
- âœ… Gradient accumulation
- âœ… Multi-GPU support (DataParallel/DistributedDataParallel ready)
- âœ… Efficient data loading with prefetching
- âœ… TensorBoard integration

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

This project builds upon insights from:

- **LPIPS** - Perceptual similarity metrics
- **FID** - Frechet Inception Distance
- **StyleGAN** - High-quality image generation
- **Shift-Tolerant LPIPS** - Robustness to transformations

Special thanks to the open-source community for providing foundational tools and datasets.

---

## ğŸ“ Contact

- **Project Lead**: Dmitrij Morgenshtern
- **GitHub**: [H1merka/TIGAS](https://github.com/H1merka/TIGAS)
- **Issues**: [GitHub Issues](https://github.com/H1merka/TIGAS/issues)

---

**Made with â¤ï¸ by the TIGAS Research Team**
