{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ TIGAS Model Training on Cloud GPU\n",
    "\n",
    "Notebook –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ TIGAS –Ω–∞ –º–æ—â–Ω—ã—Ö GPU –≤ **Kaggle** –∏–ª–∏ **Google Colab**.\n",
    "\n",
    "## –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –æ–±–ª–∞—á–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:\n",
    "- üî• **Kaggle**: Tesla P100 (16GB) –∏–ª–∏ T4 (16GB) –±–µ—Å–ø–ª–∞—Ç–Ω–æ\n",
    "- üî• **Colab**: Tesla T4 (15GB) –∏–ª–∏ K80 (12GB) –±–µ—Å–ø–ª–∞—Ç–Ω–æ\n",
    "- ‚ö° **–ë—ã—Å—Ç—Ä–æ**: ~6-12 —á–∞—Å–æ–≤ –≤–º–µ—Å—Ç–æ 5-7 –¥–Ω–µ–π –Ω–∞ —Å–ª–∞–±–æ–º GPU\n",
    "- üéØ **Batch size**: 16-32 –≤–º–µ—Å—Ç–æ 2-4\n",
    "- ‚ùÑÔ∏è **–ù–µ—Ç –ø—Ä–æ–±–ª–µ–º** —Å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π –∏ thermal throttling\n",
    "\n",
    "## –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n",
    "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç TIGAS –≤ Kaggle Dataset –∏–ª–∏ Google Drive\n",
    "2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ\n",
    "3. –î–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "4. –°–∫–∞—á–∞–π—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã (Kaggle –∏–ª–∏ Colab)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Detect platform\n",
    "IS_KAGGLE = os.path.exists('/kaggle')\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "print(\"=\"*60)\n",
    "if IS_KAGGLE:\n",
    "    print(\"üéØ –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: KAGGLE\")\n",
    "    BASE_PATH = '/kaggle'\n",
    "    DATASET_PATH = '/kaggle/input/tigas-dataset'  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –ø—É—Ç—å\n",
    "elif IS_COLAB:\n",
    "    print(\"üéØ –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: GOOGLE COLAB\")\n",
    "    BASE_PATH = '/content'\n",
    "    DATASET_PATH = '/content/TIGAS'  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –ø—É—Ç—å\n",
    "else:\n",
    "    print(\"üéØ –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: LOCAL\")\n",
    "    BASE_PATH = '.'\n",
    "    DATASET_PATH = 'C:/Dev/dataset/dataset/TIGAS_dataset/TIGAS'\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU\n",
    "import torch\n",
    "\n",
    "print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU:\")\n",
    "print(\"=\"*60)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"   CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"‚ùå GPU –ù–ï –¥–æ—Å—Ç—É–ø–µ–Ω! –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU (–º–µ–¥–ª–µ–Ω–Ω–æ)\")\n",
    "    print(\"   –í–∫–ª—é—á–∏—Ç–µ GPU –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    device = 'cpu'\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)\n",
    "print(\"\\nüì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...\")\n",
    "!pip install -q pandas pillow tqdm tensorboard\n",
    "print(\"‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞ TIGAS\n",
    "\n",
    "### –í–∞—Ä–∏–∞–Ω—Ç 1: –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ GitHub (–µ—Å–ª–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø—É–±–ª–∏—á–Ω—ã–π)\n",
    "```python\n",
    "!git clone https://github.com/YOUR_USERNAME/TIGAS.git\n",
    "%cd TIGAS\n",
    "```\n",
    "\n",
    "### –í–∞—Ä–∏–∞–Ω—Ç 2: Upload —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞\n",
    "- –í Colab: Files ‚Üí Upload\n",
    "- –í Kaggle: Add Data ‚Üí Upload Dataset\n",
    "\n",
    "### –í–∞—Ä–∏–∞–Ω—Ç 3: –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ –Ω–∞–ø—Ä—è–º—É—é (–≤—ã–±–µ—Ä–∏—Ç–µ —ç—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π\n",
    "os.makedirs('tigas/models', exist_ok=True)\n",
    "os.makedirs('tigas/data', exist_ok=True)\n",
    "os.makedirs('tigas/training', exist_ok=True)\n",
    "os.makedirs('tigas/utils', exist_ok=True)\n",
    "os.makedirs('checkpoints/logs', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞\")\n",
    "print(\"\\n‚ö†Ô∏è –í–ê–ñ–ù–û: –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ TIGAS:\")\n",
    "print(\"   - tigas/models/*.py\")\n",
    "print(\"   - tigas/data/*.py\")\n",
    "print(\"   - tigas/training/*.py\")\n",
    "print(\"   - tigas/utils/*.py\")\n",
    "print(\"\\n–ò–ª–∏ –∫–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:\")\n",
    "print(\"   !git clone YOUR_REPO_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ TIGAS\n",
    "\n",
    "**–î–ª—è Kaggle:**\n",
    "1. –î–æ–±–∞–≤—å—Ç–µ TIGAS dataset –≤ Kaggle Datasets\n",
    "2. Add Data ‚Üí Search ‚Üí Select your dataset\n",
    "3. –ü—É—Ç—å –±—É–¥–µ—Ç: `/kaggle/input/tigas-dataset/TIGAS`\n",
    "\n",
    "**–î–ª—è Colab:**\n",
    "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ Google Drive\n",
    "2. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ Drive (–∑–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É –Ω–∏–∂–µ)\n",
    "3. –ü—É—Ç—å –±—É–¥–µ—Ç: `/content/drive/MyDrive/TIGAS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–ª—è Google Colab: –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Google Drive\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úÖ Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω\")\n",
    "    DATASET_PATH = '/content/drive/MyDrive/TIGAS'  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –ø—É—Ç—å\n",
    "    print(f\"üìÅ –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset_path = Path(DATASET_PATH)\n",
    "if dataset_path.exists():\n",
    "    print(f\"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –Ω–∞–π–¥–µ–Ω: {dataset_path}\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã\n",
    "    train_csv = dataset_path / 'train' / 'annotations01.csv'\n",
    "    val_csv = dataset_path / 'val' / 'annotations01.csv'\n",
    "    test_csv = dataset_path / 'test' / 'annotations01.csv'\n",
    "    \n",
    "    if train_csv.exists():\n",
    "        import pandas as pd\n",
    "        train_count = len(pd.read_csv(train_csv))\n",
    "        val_count = len(pd.read_csv(val_csv)) if val_csv.exists() else 0\n",
    "        test_count = len(pd.read_csv(test_csv)) if test_csv.exists() else 0\n",
    "        \n",
    "        print(f\"   üìä Train: {train_count:,} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "        print(f\"   üìä Val: {val_count:,} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "        print(f\"   üìä Test: {test_count:,} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "        print(f\"   üìä –í—Å–µ–≥–æ: {train_count + val_count + test_count:,} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è –§–∞–π–ª—ã annotations01.csv –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!\")\n",
    "else:\n",
    "    print(f\"‚ùå –î–∞—Ç–∞—Å–µ—Ç –ù–ï –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {dataset_path}\")\n",
    "    print(\"   –ò–∑–º–µ–Ω–∏—Ç–µ DATASET_PATH –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è –ø–æ–¥ –º–æ—â–Ω—ã–π GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –º–æ—â–Ω–æ–≥–æ GPU)\n",
    "CONFIG = {\n",
    "    # –ü—É—Ç–∏\n",
    "    'data_root': DATASET_PATH,\n",
    "    'output_dir': f'{BASE_PATH}/working/checkpoints',\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª—å\n",
    "    'img_size': 256,\n",
    "    'base_channels': 32,\n",
    "    'feature_dim': 256,\n",
    "    'num_attention_heads': 8,\n",
    "    'dropout': 0.1,\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    'batch_size': 16,  # –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 32 –Ω–∞ –º–æ—â–Ω–æ–º GPU\n",
    "    'num_epochs': 80,\n",
    "    'learning_rate': 0.0001,\n",
    "    'num_workers': 4,\n",
    "    'device': device,\n",
    "    \n",
    "    # Data augmentation\n",
    "    'augment_level': 'medium',\n",
    "    \n",
    "    # Loss\n",
    "    'regression_weight': 1.0,\n",
    "    'classification_weight': 0.5,\n",
    "    'ranking_weight': 0.3,\n",
    "    'use_smooth_l1': True,\n",
    "    'margin': 0.5,\n",
    "    \n",
    "    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\n",
    "    'optimizer': 'adamw',\n",
    "    'weight_decay': 0.0001,\n",
    "    'scheduler': 'cosine',\n",
    "    'warmup_epochs': 5,\n",
    "    'min_lr': 0.000001,\n",
    "    \n",
    "    # Training\n",
    "    'use_amp': True,  # Mixed Precision\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'early_stopping_patience': 15,\n",
    "}\n",
    "\n",
    "# –í—ã–≤–æ–¥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n",
    "print(\"\\n‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è:\")\n",
    "print(\"=\"*60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key:30s}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π TIGAS\n",
    "import sys\n",
    "sys.path.insert(0, BASE_PATH if BASE_PATH != '.' else os.getcwd())\n",
    "\n",
    "from tigas.models.tigas_model import create_tigas_model\n",
    "from tigas.data.loaders import create_dataloaders_from_csv\n",
    "from tigas.training.trainer import TIGASTrainer\n",
    "from tigas.training.losses import CombinedLoss\n",
    "\n",
    "print(\"‚úÖ –ú–æ–¥—É–ª–∏ TIGAS –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "print(\"\\nüèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ TIGAS...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = create_tigas_model(\n",
    "    img_size=CONFIG['img_size'],\n",
    "    base_channels=CONFIG['base_channels'],\n",
    "    feature_dim=CONFIG['feature_dim'],\n",
    "    num_attention_heads=CONFIG['num_attention_heads'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "\n",
    "model = model.to(CONFIG['device'])\n",
    "\n",
    "model_info = model.get_model_size()\n",
    "print(f\"   ‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞:\")\n",
    "print(f\"      –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {model_info['total_parameters']:,}\")\n",
    "print(f\"      –û–±—É—á–∞–µ–º—ã—Ö: {model_info['trainable_parameters']:,}\")\n",
    "print(f\"      –†–∞–∑–º–µ—Ä: {model_info['model_size_mb']:.2f} MB\")\n",
    "print(f\"      –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {next(model.parameters()).device}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ dataloaders\n",
    "print(\"\\nüìä –°–æ–∑–¥–∞–Ω–∏–µ dataloaders...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataloaders = create_dataloaders_from_csv(\n",
    "    data_root=CONFIG['data_root'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    img_size=CONFIG['img_size'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    augment_level=CONFIG['augment_level'],\n",
    "    pin_memory=True if CONFIG['device'] == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Dataloaders —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ loss function\n",
    "loss_fn = CombinedLoss(\n",
    "    use_tigas_loss=True,\n",
    "    use_contrastive=False,\n",
    "    tigas_loss_config={\n",
    "        'regression_weight': CONFIG['regression_weight'],\n",
    "        'classification_weight': CONFIG['classification_weight'],\n",
    "        'ranking_weight': CONFIG['ranking_weight'],\n",
    "        'use_smooth_l1': CONFIG['use_smooth_l1'],\n",
    "        'margin': CONFIG['margin']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Loss function —Å–æ–∑–¥–∞–Ω–∞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–µ—Ä–∞\n",
    "print(\"\\nüéì –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "\n",
    "trainer = TIGASTrainer(\n",
    "    model=model,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer_config={\n",
    "        'optimizer_type': CONFIG['optimizer'],\n",
    "        'learning_rate': CONFIG['learning_rate'],\n",
    "        'weight_decay': CONFIG['weight_decay']\n",
    "    },\n",
    "    scheduler_config={\n",
    "        'scheduler_type': CONFIG['scheduler'],\n",
    "        'num_epochs': CONFIG['num_epochs'],\n",
    "        'warmup_epochs': CONFIG['warmup_epochs'],\n",
    "        'min_lr': CONFIG['min_lr']\n",
    "    },\n",
    "    device=CONFIG['device'],\n",
    "    output_dir=CONFIG['output_dir'],\n",
    "    use_amp=CONFIG['use_amp'],\n",
    "    gradient_accumulation_steps=CONFIG['gradient_accumulation_steps'],\n",
    "    max_grad_norm=CONFIG['max_grad_norm'],\n",
    "    log_interval=10,\n",
    "    save_interval=5,\n",
    "    validate_interval=1,\n",
    "    early_stopping_patience=CONFIG['early_stopping_patience'],\n",
    "    use_tensorboard=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ –¢—Ä–µ–Ω–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n",
    "print(f\"   –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –≤: {CONFIG['output_dir']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "‚è∞ **–û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:**\n",
    "- Tesla P100 (16GB): ~6-8 —á–∞—Å–æ–≤ –¥–ª—è 50-80 —ç–ø–æ—Ö\n",
    "- Tesla T4 (16GB): ~8-12 —á–∞—Å–æ–≤ –¥–ª—è 50-80 —ç–ø–æ—Ö\n",
    "- Tesla K80 (12GB): ~12-18 —á–∞—Å–æ–≤ –¥–ª—è 50-80 —ç–ø–æ—Ö\n",
    "\n",
    "üí° **–°–æ–≤–µ—Ç—ã:**\n",
    "- –°–ª–µ–¥–∏—Ç–µ –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n",
    "- –ú–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è, –µ—Å–ª–∏ validation loss –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è 15 —ç–ø–æ—Ö\n",
    "- –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "print(\"\\nüöÄ –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   –≠–ø–æ—Ö: {CONFIG['num_epochs']}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   Device: {CONFIG['device']}\")\n",
    "print(f\"   Mixed Precision: {CONFIG['use_amp']}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚è∞ –ü—Ä–∏–≥–æ—Ç–æ–≤—å—Ç–µ –∫–æ—Ñ–µ - —ç—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤...\\n\")\n",
    "\n",
    "try:\n",
    "    trainer.train(\n",
    "        num_epochs=CONFIG['num_epochs'],\n",
    "        resume_from=None\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {CONFIG['output_dir']}\")\n",
    "    print(\"   - best_model.pt: –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ validation –º–µ—Ç—Ä–∏–∫–∞–º\")\n",
    "    print(\"   - latest_model.pt: –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç\")\n",
    "    print(\"   - logs/: –ª–æ–≥–∏ TensorBoard\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\")\n",
    "    print(f\"   –ß–µ–∫–ø–æ–∏–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {CONFIG['output_dir']}/latest_model.pt\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ TensorBoard –≤ notebook\n",
    "if IS_COLAB:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir {CONFIG['output_dir']}/logs\n",
    "elif IS_KAGGLE:\n",
    "    print(\"üìä TensorBoard –ª–æ–≥–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –≤: {CONFIG['output_dir']}/logs\")\n",
    "    print(\"   –°–∫–∞—á–∞–π—Ç–µ –ª–æ–≥–∏ –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –ª–æ–∫–∞–ª—å–Ω–æ: tensorboard --logdir logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "best_model_path = Path(CONFIG['output_dir']) / 'best_model.pt'\n",
    "if best_model_path.exists():\n",
    "    checkpoint = torch.load(best_model_path, map_location=CONFIG['device'])\n",
    "    \n",
    "    print(\"\\nüìä –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏:\")\n",
    "    print(\"=\"*60)\n",
    "    if 'metrics' in checkpoint:\n",
    "        for key, value in checkpoint['metrics'].items():\n",
    "            print(f\"   {key:30s}: {value:.4f}\")\n",
    "    print(f\"\\n   –≠–ø–æ—Ö–∞: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–∂–∞—Ç–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è\n",
    "import shutil\n",
    "\n",
    "output_archive = f'{BASE_PATH}/working/tigas_trained_model.zip'\n",
    "\n",
    "print(\"üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏...\")\n",
    "shutil.make_archive(\n",
    "    base_name=output_archive.replace('.zip', ''),\n",
    "    format='zip',\n",
    "    root_dir=CONFIG['output_dir']\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ –ê—Ä—Ö–∏–≤ —Å–æ–∑–¥–∞–Ω: {output_archive}\")\n",
    "print(f\"   –†–∞–∑–º–µ—Ä: {Path(output_archive).stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"\\n‚¨áÔ∏è –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞...\")\n",
    "    files.download(output_archive)\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nüíæ –î–ª—è Kaggle: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ /kaggle/working/\")\n",
    "    print(\"   –û–Ω–∏ –±—É–¥—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è kernel –≤ Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ –ì–æ—Ç–æ–≤–æ!\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.\n",
    "\n",
    "### –ß—Ç–æ –¥–∞–ª—å—à–µ?\n",
    "1. –°–∫–∞—á–∞–π—Ç–µ `tigas_trained_model.zip`\n",
    "2. –†–∞—Å–ø–∞–∫—É–π—Ç–µ –∞—Ä—Ö–∏–≤\n",
    "3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `best_model.pt` –¥–ª—è inference\n",
    "\n",
    "### –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å?\n",
    "```python\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "checkpoint = torch.load('best_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    prediction = output['score']  # 0.0 = fake, 1.0 = real\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**–°–ø–∞—Å–∏–±–æ –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ TIGAS! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
