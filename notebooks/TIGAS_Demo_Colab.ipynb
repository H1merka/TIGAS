{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c0a3a1",
   "metadata": {},
   "source": [
    "## âš™ï¸ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ - Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¿Ğ¾Ğ´ ÑĞ²Ğ¾Ğ¸ Ğ½ÑƒĞ¶Ğ´Ñ‹\n",
    "# =============================================================================\n",
    "\n",
    "# Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ´ĞµĞ¼Ğ¾ (True = Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ ~15 Ğ¼Ğ¸Ğ½, False = Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ~50 Ğ¼Ğ¸Ğ½)\n",
    "DEMO_MODE = True\n",
    "\n",
    "# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°\n",
    "IMAGE_SIZE = 64          # Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ (64x64 Ğ´Ğ»Ñ CelebA)\n",
    "MAX_IMAGES = 20000 if DEMO_MODE else None  # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹\n",
    "\n",
    "# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 15 if DEMO_MODE else 30\n",
    "LEARNING_RATE = 0.0002\n",
    "LATENT_DIM = 100         # Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°\n",
    "\n",
    "# Ğ’ĞµÑĞ° loss Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹\n",
    "TIGAS_LOSS_WEIGHT = 0.1  # Ğ’ĞµÑ TIGAS loss Ğ² Ğ¾Ğ±Ñ‰ĞµĞ¼ loss Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°\n",
    "\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Ğ ĞµĞ¶Ğ¸Ğ¼: {'Ğ”Ğ•ĞœĞ (Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹)' if DEMO_MODE else 'ĞŸĞĞ›ĞĞ«Ğ™'}\")\n",
    "print(f\"Ğ­Ğ¿Ğ¾Ñ…: {NUM_EPOCHS}\")\n",
    "print(f\"Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹: {MAX_IMAGES if MAX_IMAGES else 'Ğ²ÑĞµ'}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c5872",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 1. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5eabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ GPU\n",
    "import subprocess\n",
    "result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], \n",
    "                       capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(f\"âœ… GPU Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½: {result.stdout.strip()}\")\n",
    "else:\n",
    "    print(\"âŒ GPU Ğ½Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½! ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ¸Ñ‚Ğµ runtime Ğ½Ğ° GPU.\")\n",
    "    print(\"   Runtime â†’ Change runtime type â†’ T4 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14064c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° PyTorch Ñ CUDA (Colab Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ ÑƒĞ¶Ğµ Ğ¸Ğ¼ĞµĞµÑ‚, Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ğ¼ Ğ´Ğ»Ñ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸)\n",
    "!pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° TIGAS Ñ TestPyPI\n",
    "!pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ tigas-metric\n",
    "\n",
    "# Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "from tigas import TIGAS, __version__ as tigas_version\n",
    "print(f\"\\nTIGAS version: {tigas_version}\")\n",
    "print(\"\\nâœ… Ğ’ÑĞµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca3c0a",
   "metadata": {},
   "source": [
    "## ğŸ” 2. Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° TIGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee367e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ TIGAS (Ğ°Ğ²Ñ‚Ğ¾Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ HuggingFace)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tigas = TIGAS(auto_download=True, device=device)\n",
    "print(f\"\\nâœ… TIGAS Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ½Ğ° {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1344303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸\n",
    "os.makedirs('demo_images', exist_ok=True)\n",
    "\n",
    "# Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ğ¸ (Ñ Unsplash - Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ)\n",
    "real_images_urls = [\n",
    "    ('https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=256&h=256&fit=crop', 'real_1.jpg'),\n",
    "    ('https://images.unsplash.com/photo-1494790108377-be9c29b29330?w=256&h=256&fit=crop', 'real_2.jpg'),\n",
    "    ('https://images.unsplash.com/photo-1500648767791-00dcc994a43e?w=256&h=256&fit=crop', 'real_3.jpg'),\n",
    "]\n",
    "\n",
    "print(\"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹...\")\n",
    "for url, filename in real_images_urls:\n",
    "    path = f'demo_images/{filename}'\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "            print(f\"  âœ“ {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ \"Ñ„ĞµĞ¹ĞºĞ¾Ğ²Ñ‹Ğµ\" Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ (ÑˆÑƒĞ¼ Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹)\n",
    "def create_fake_images():\n",
    "    fakes = []\n",
    "    \n",
    "    # 1. Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼\n",
    "    noise = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "    fakes.append(('Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼', noise))\n",
    "    \n",
    "    # 2. Ğ“Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚\n",
    "    gradient = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "    for i in range(256):\n",
    "        gradient[i, :, 0] = i\n",
    "        gradient[:, i, 1] = i\n",
    "    fakes.append(('Ğ“Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚', gradient))\n",
    "    \n",
    "    # 3. Ğ¨Ğ°Ñ…Ğ¼Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½\n",
    "    checker = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            if (i // 32 + j // 32) % 2 == 0:\n",
    "                checker[i, j] = [255, 255, 255]\n",
    "    fakes.append(('Ğ¨Ğ°Ñ…Ğ¼Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½', checker))\n",
    "    \n",
    "    return fakes\n",
    "\n",
    "fake_images = create_fake_images()\n",
    "print(f\"âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ {len(fake_images)} ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5962e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĞÑ†ĞµĞ½ĞºĞ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ĞĞ¦Ğ•ĞĞšĞ Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ¥ Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ™\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "real_scores = []\n",
    "real_imgs = []\n",
    "\n",
    "for url, filename in real_images_urls:\n",
    "    path = f'demo_images/{filename}'\n",
    "    if os.path.exists(path):\n",
    "        score = tigas(path)\n",
    "        real_scores.append(score.item())\n",
    "        real_imgs.append(Image.open(path))\n",
    "        print(f\"{filename}: TIGAS = {score.item():.4f}\")\n",
    "\n",
    "if real_scores:\n",
    "    print(f\"\\nĞ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ´Ğ»Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ…: {np.mean(real_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c391c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĞÑ†ĞµĞ½ĞºĞ° ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ĞĞ¦Ğ•ĞĞšĞ Ğ¡Ğ˜ĞĞ¢Ğ•Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ¥ Ğ˜Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ™\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "fake_scores = []\n",
    "\n",
    "for name, img_array in fake_images:\n",
    "    img = Image.fromarray(img_array)\n",
    "    score = tigas(img)\n",
    "    fake_scores.append(score.item())\n",
    "    print(f\"{name}: TIGAS = {score.item():.4f}\")\n",
    "\n",
    "print(f\"\\nĞ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ…: {np.mean(fake_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\n",
    "for i, (img, score) in enumerate(zip(real_imgs[:3], real_scores[:3])):\n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f'Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ\\nTIGAS: {score:.3f}', fontsize=12)\n",
    "    axes[0, i].axis('off')\n",
    "    # Ğ¦Ğ²ĞµÑ‚Ğ¾Ğ²Ğ°Ñ Ñ€Ğ°Ğ¼ĞºĞ°\n",
    "    for spine in axes[0, i].spines.values():\n",
    "        spine.set_edgecolor('green')\n",
    "        spine.set_linewidth(3)\n",
    "\n",
    "# Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\n",
    "for i, ((name, img_array), score) in enumerate(zip(fake_images[:3], fake_scores[:3])):\n",
    "    axes[1, i].imshow(img_array)\n",
    "    axes[1, i].set_title(f'{name}\\nTIGAS: {score:.3f}', fontsize=12)\n",
    "    axes[1, i].axis('off')\n",
    "    for spine in axes[1, i].spines.values():\n",
    "        spine.set_edgecolor('red')\n",
    "        spine.set_linewidth(3)\n",
    "\n",
    "plt.suptitle('TIGAS: ĞÑ†ĞµĞ½ĞºĞ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… vs ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹\\n(Ğ’Ñ‹ÑˆĞµ = Ğ±Ğ¾Ğ»ĞµĞµ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Ğ’Ñ‹Ğ²Ğ¾Ğ´: TIGAS Ğ´Ğ°Ñ‘Ñ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ñ„Ğ¾Ñ‚Ğ¾ Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ¸Ğµ â€” ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f7e902",
   "metadata": {},
   "source": [
    "## ğŸ¨ 3. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bdd068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ CelebA\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ² [-1, 1]\n",
    "])\n",
    "\n",
    "print(f\"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° CelebA Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° (ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼Ğ¸Ğ½ÑƒÑ‚)...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa262545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° CelebA\n",
    "# Ğ’ Colab Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸\n",
    "try:\n",
    "    dataset = datasets.CelebA(\n",
    "        root='./data',\n",
    "        split='train',\n",
    "        transform=transform,\n",
    "        download=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ CelebA: {e}\")\n",
    "    print(\"\\nĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ‡ĞµÑ€ĞµĞ· gdown...\")\n",
    "    \n",
    "    # ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· gdown\n",
    "    !mkdir -p ./data/celeba\n",
    "    !gdown --fuzzy \"https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\" -O ./data/celeba/img_align_celeba.zip\n",
    "    !unzip -q ./data/celeba/img_align_celeba.zip -d ./data/celeba/\n",
    "    \n",
    "    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ImageFolder ĞºĞ°Ğº Ğ·Ğ°Ğ¿Ğ°ÑĞ½Ğ¾Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root='./data/celeba',\n",
    "        transform=transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e65bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ´ĞµĞ¼Ğ¾ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°\n",
    "if MAX_IMAGES and len(dataset) > MAX_IMAGES:\n",
    "    indices = torch.randperm(len(dataset))[:MAX_IMAGES]\n",
    "    dataset = Subset(dataset, indices)\n",
    "    print(f\"âœ… Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ´Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾: {len(dataset)} Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹\")\n",
    "else:\n",
    "    print(f\"âœ… Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ²ĞµÑÑŒ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚: {len(dataset)} Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹\")\n",
    "\n",
    "# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ DataLoader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Ğ‘Ğ°Ñ‚Ñ‡ĞµĞ¹ Ğ² ÑĞ¿Ğ¾Ñ…Ğµ: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¸Ğ· Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°\n",
    "real_batch = next(iter(dataloader))\n",
    "if isinstance(real_batch, (list, tuple)):\n",
    "    real_batch = real_batch[0]  # CelebA Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ (images, attributes)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    img = real_batch[i].permute(1, 2, 0).numpy()\n",
    "    img = (img + 1) / 2  # Ğ”ĞµĞ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· [-1,1] Ğ² [0,1]\n",
    "    plt.imshow(np.clip(img, 0, 1))\n",
    "    plt.axis('off')\n",
    "plt.suptitle('ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ· CelebA Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4461c40",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ 4. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ²\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"DCGAN Generator: z (latent) â†’ 64x64 RGB image\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, ngf=64):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input: latent_dim x 1 x 1\n",
    "            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # State: (ngf*8) x 4 x 4\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # State: (ngf*4) x 8 x 8\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # State: (ngf*2) x 16 x 16\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # State: ngf x 32 x 32\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # Output: 3 x 64 x 64\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.main(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"DCGAN Discriminator: 64x64 RGB image â†’ real/fake score\"\"\"\n",
    "    \n",
    "    def __init__(self, ndf=64):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input: 3 x 64 x 64\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State: ndf x 32 x 32\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State: (ndf*2) x 16 x 16\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State: (ndf*4) x 8 x 8\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State: (ndf*8) x 4 x 4\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # Output: 1 x 1 x 1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
    "generator = Generator(LATENT_DIM).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ²\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "print(f\"Generator Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "print(f\"Discriminator Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²: {sum(p.numel() for p in discriminator.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ (Ğ´Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ)\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(8, LATENT_DIM, 1, 1, device=device)\n",
    "    fake_images_test = generator(z)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i in range(8):\n",
    "    plt.subplot(1, 8, i + 1)\n",
    "    img = fake_images_test[i].cpu().permute(1, 2, 0).numpy()\n",
    "    img = (img + 1) / 2\n",
    "    plt.imshow(np.clip(img, 0, 1))\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ”Ğ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ²ĞµÑĞ°)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172163b",
   "metadata": {},
   "source": [
    "## ğŸš€ 5. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ GAN Ñ TIGAS Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Loss Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ñ‹\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "# Ğ¤Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°\n",
    "fixed_noise = torch.randn(64, LATENT_DIM, 1, 1, device=device)\n",
    "\n",
    "# ĞœĞµÑ‚ĞºĞ¸\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ TIGAS\n",
    "# TIGAS Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµÑ‚ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ [-1, 1] Ğ¸ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ 256x256\n",
    "def prepare_for_tigas(images):\n",
    "    \"\"\"ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ TIGAS (resize Ğ´Ğ¾ 256x256)\"\"\"\n",
    "    # images ÑƒĞ¶Ğµ Ğ² [-1, 1], Ğ½ÑƒĞ¶ĞµĞ½ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ resize\n",
    "    return TF.resize(images, [256, 256], antialias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3eee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n",
    "history = {\n",
    "    'D_loss': [],\n",
    "    'G_loss': [],\n",
    "    'G_loss_adv': [],\n",
    "    'G_loss_tigas': [],\n",
    "    'D_real': [],\n",
    "    'D_fake': [],\n",
    "    'tigas_score_fake': [],\n",
    "    'tigas_score_real': []\n",
    "}\n",
    "\n",
    "# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ¿Ğ¾ ÑĞ¿Ğ¾Ñ…Ğ°Ğ¼\n",
    "generated_images_history = []\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ĞĞĞ§ĞĞ›Ğ ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ¯\")\n",
    "print(f\"Ğ­Ğ¿Ğ¾Ñ…: {NUM_EPOCHS}, Ğ‘Ğ°Ñ‚Ñ‡ĞµĞ¹: {len(dataloader)}, TIGAS weight: {TIGAS_LOSS_WEIGHT}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7621a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ†Ğ¸ĞºĞ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_D_loss = []\n",
    "    epoch_G_loss = []\n",
    "    epoch_G_adv = []\n",
    "    epoch_G_tigas = []\n",
    "    epoch_D_real = []\n",
    "    epoch_D_fake = []\n",
    "    epoch_tigas_fake = []\n",
    "    epoch_tigas_real = []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    \n",
    "    for i, batch in enumerate(pbar):\n",
    "        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\n",
    "        if isinstance(batch, (list, tuple)):\n",
    "            real_images = batch[0].to(device)\n",
    "        else:\n",
    "            real_images = batch.to(device)\n",
    "        \n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # =====================\n",
    "        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Discriminator\n",
    "        # =====================\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\n",
    "        label_real = torch.full((batch_size,), real_label, device=device, dtype=torch.float)\n",
    "        output_real = discriminator(real_images)\n",
    "        loss_D_real = criterion(output_real, label_real)\n",
    "        loss_D_real.backward()\n",
    "        D_real = output_real.mean().item()\n",
    "        \n",
    "        # Ğ¤ĞµĞ¹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\n",
    "        noise = torch.randn(batch_size, LATENT_DIM, 1, 1, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        label_fake = torch.full((batch_size,), fake_label, device=device, dtype=torch.float)\n",
    "        output_fake = discriminator(fake_images.detach())\n",
    "        loss_D_fake = criterion(output_fake, label_fake)\n",
    "        loss_D_fake.backward()\n",
    "        D_fake = output_fake.mean().item()\n",
    "        \n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # =====================\n",
    "        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Generator\n",
    "        # =====================\n",
    "        generator.zero_grad()\n",
    "        \n",
    "        # Adversarial loss (Ğ¾Ğ±Ğ¼Ğ°Ğ½ÑƒÑ‚ÑŒ discriminator)\n",
    "        output = discriminator(fake_images)\n",
    "        loss_G_adv = criterion(output, label_real)  # Ğ¥Ğ¾Ñ‚Ğ¸Ğ¼, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ D Ğ´ÑƒĞ¼Ğ°Ğ», Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ\n",
    "        \n",
    "        # TIGAS loss (Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ TIGAS)\n",
    "        fake_for_tigas = prepare_for_tigas(fake_images)\n",
    "        with torch.no_grad():  # TIGAS Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸, Ğ½Ğµ Ğ´Ğ»Ñ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµĞ³Ğ¾\n",
    "            tigas_scores_fake = tigas(fake_for_tigas)\n",
    "        \n",
    "        # Ğ”Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: Ñ…Ğ¾Ñ‚Ğ¸Ğ¼ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ TIGAS score â†’ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ (1 - score)\n",
    "        # ĞĞ¾ TIGAS Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ´Ğ¸Ñ„Ñ„ĞµÑ€ĞµĞ½Ñ†Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¼ Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾\n",
    "        # Ğ—Ğ´ĞµÑÑŒ Ğ¼Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ TIGAS ĞºĞ°Ğº Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ»\n",
    "        fake_for_tigas_grad = prepare_for_tigas(fake_images)\n",
    "        tigas_scores_grad = tigas(fake_for_tigas_grad)\n",
    "        loss_G_tigas = (1.0 - tigas_scores_grad).mean()  # ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ (1 - score)\n",
    "        \n",
    "        # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ loss Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°\n",
    "        loss_G = loss_G_adv + TIGAS_LOSS_WEIGHT * loss_G_tigas\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # ĞÑ†ĞµĞ½ĞºĞ° TIGAS Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… (Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°)\n",
    "        if i % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                real_for_tigas = prepare_for_tigas(real_images[:8])\n",
    "                tigas_scores_real = tigas(real_for_tigas).mean().item()\n",
    "        else:\n",
    "            tigas_scores_real = epoch_tigas_real[-1] if epoch_tigas_real else 0.5\n",
    "        \n",
    "        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸\n",
    "        epoch_D_loss.append(loss_D.item())\n",
    "        epoch_G_loss.append(loss_G.item())\n",
    "        epoch_G_adv.append(loss_G_adv.item())\n",
    "        epoch_G_tigas.append(loss_G_tigas.item())\n",
    "        epoch_D_real.append(D_real)\n",
    "        epoch_D_fake.append(D_fake)\n",
    "        epoch_tigas_fake.append(tigas_scores_fake.mean().item())\n",
    "        epoch_tigas_real.append(tigas_scores_real)\n",
    "        \n",
    "        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ progress bar\n",
    "        pbar.set_postfix({\n",
    "            'D_loss': f'{loss_D.item():.3f}',\n",
    "            'G_loss': f'{loss_G.item():.3f}',\n",
    "            'TIGAS': f'{tigas_scores_fake.mean().item():.3f}'\n",
    "        })\n",
    "    \n",
    "    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑÑ€ĞµĞ´Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ·Ğ° ÑĞ¿Ğ¾Ñ…Ñƒ\n",
    "    history['D_loss'].append(np.mean(epoch_D_loss))\n",
    "    history['G_loss'].append(np.mean(epoch_G_loss))\n",
    "    history['G_loss_adv'].append(np.mean(epoch_G_adv))\n",
    "    history['G_loss_tigas'].append(np.mean(epoch_G_tigas))\n",
    "    history['D_real'].append(np.mean(epoch_D_real))\n",
    "    history['D_fake'].append(np.mean(epoch_D_fake))\n",
    "    history['tigas_score_fake'].append(np.mean(epoch_tigas_fake))\n",
    "    history['tigas_score_real'].append(np.mean(epoch_tigas_real))\n",
    "    \n",
    "    # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\n",
    "    with torch.no_grad():\n",
    "        fake_samples = generator(fixed_noise).cpu()\n",
    "        generated_images_history.append(fake_samples[:16])\n",
    "    \n",
    "    # Ğ’Ñ‹Ğ²Ğ¾Ğ´ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}:\")\n",
    "    print(f\"  D_loss: {history['D_loss'][-1]:.4f} | G_loss: {history['G_loss'][-1]:.4f}\")\n",
    "    print(f\"  D(real): {history['D_real'][-1]:.4f} | D(fake): {history['D_fake'][-1]:.4f}\")\n",
    "    print(f\"  TIGAS(fake): {history['tigas_score_fake'][-1]:.4f} | TIGAS(real): {history['tigas_score_real'][-1]:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ• Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc7ed4",
   "metadata": {},
   "source": [
    "## ğŸ“Š 6. Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afeaea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "epochs_range = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "# 1. Loss\n",
    "axes[0, 0].plot(epochs_range, history['D_loss'], 'b-', label='Discriminator', linewidth=2)\n",
    "axes[0, 0].plot(epochs_range, history['G_loss'], 'r-', label='Generator', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Generator Loss ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹\n",
    "axes[0, 1].plot(epochs_range, history['G_loss_adv'], 'g-', label='Adversarial', linewidth=2)\n",
    "axes[0, 1].plot(epochs_range, history['G_loss_tigas'], 'm-', label=f'TIGAS (Ã—{TIGAS_LOSS_WEIGHT})', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Generator Loss Components')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Discriminator Ğ²Ñ‹Ñ…Ğ¾Ğ´Ñ‹\n",
    "axes[1, 0].plot(epochs_range, history['D_real'], 'g-', label='D(real)', linewidth=2)\n",
    "axes[1, 0].plot(epochs_range, history['D_fake'], 'r-', label='D(fake)', linewidth=2)\n",
    "axes[1, 0].axhline(y=0.5, color='k', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Discriminator Output')\n",
    "axes[1, 0].set_title('Discriminator Predictions')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "\n",
    "# 4. TIGAS Score\n",
    "axes[1, 1].plot(epochs_range, history['tigas_score_real'], 'g-', label='TIGAS(real)', linewidth=2)\n",
    "axes[1, 1].plot(epochs_range, history['tigas_score_fake'], 'r-', label='TIGAS(fake)', linewidth=2)\n",
    "axes[1, 1].fill_between(epochs_range, history['tigas_score_fake'], alpha=0.3, color='red')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('TIGAS Score')\n",
    "axes[1, 1].set_title('TIGAS Score Evolution')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ TIGAS score ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ­Ğ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ÑĞ¿Ğ¾Ñ…Ğ°Ğ¼\n",
    "num_snapshots = min(5, len(generated_images_history))\n",
    "snapshot_indices = np.linspace(0, len(generated_images_history) - 1, num_snapshots, dtype=int)\n",
    "\n",
    "fig, axes = plt.subplots(num_snapshots, 8, figsize=(16, num_snapshots * 2))\n",
    "\n",
    "for row, idx in enumerate(snapshot_indices):\n",
    "    epoch_num = idx + 1\n",
    "    images = generated_images_history[idx]\n",
    "    \n",
    "    for col in range(8):\n",
    "        ax = axes[row, col] if num_snapshots > 1 else axes[col]\n",
    "        img = images[col].permute(1, 2, 0).numpy()\n",
    "        img = (img + 1) / 2\n",
    "        ax.imshow(np.clip(img, 0, 1))\n",
    "        ax.axis('off')\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(f'Epoch {epoch_num}', fontsize=12, rotation=0, labelpad=40)\n",
    "\n",
    "plt.suptitle('Ğ­Ğ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ÑĞ¿Ğ¾Ñ…Ğ°Ğ¼', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('generation_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11617df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ TIGAS Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(16, LATENT_DIM, 1, 1, device=device)\n",
    "    final_fakes = generator(z)\n",
    "    \n",
    "    # ĞÑ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµĞ¼ ĞºĞ°Ğ¶Ğ´Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ\n",
    "    final_fakes_256 = prepare_for_tigas(final_fakes)\n",
    "    final_scores = tigas(final_fakes_256)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = final_fakes[i].cpu().permute(1, 2, 0).numpy()\n",
    "    img = (img + 1) / 2\n",
    "    ax.imshow(np.clip(img, 0, 1))\n",
    "    score = final_scores[i].item()\n",
    "    color = 'green' if score > 0.5 else 'orange' if score > 0.3 else 'red'\n",
    "    ax.set_title(f'TIGAS: {score:.3f}', fontsize=11, color=color, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(f'Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ (ÑÑ€ĞµĞ´Ğ½Ğ¸Ğ¹ TIGAS: {final_scores.mean().item():.3f})', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_generations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° TIGAS Ğ´Ğ»Ñ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹:\")\n",
    "print(f\"   Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ: {final_scores.mean().item():.4f}\")\n",
    "print(f\"   ĞœĞ¸Ğ½: {final_scores.min().item():.4f}\")\n",
    "print(f\"   ĞœĞ°ĞºÑ: {final_scores.max().item():.4f}\")\n",
    "print(f\"   Std: {final_scores.std().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ: Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ vs ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 5))\n",
    "\n",
    "# Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ\n",
    "real_sample = next(iter(dataloader))\n",
    "if isinstance(real_sample, (list, tuple)):\n",
    "    real_sample = real_sample[0]\n",
    "real_sample = real_sample[:8].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    real_256 = prepare_for_tigas(real_sample)\n",
    "    real_tigas = tigas(real_256)\n",
    "\n",
    "for i in range(8):\n",
    "    img = real_sample[i].cpu().permute(1, 2, 0).numpy()\n",
    "    img = (img + 1) / 2\n",
    "    axes[0, i].imshow(np.clip(img, 0, 1))\n",
    "    axes[0, i].set_title(f'{real_tigas[i].item():.3f}', fontsize=10, color='green')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ', fontsize=12, rotation=0, labelpad=50)\n",
    "\n",
    "# Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ\n",
    "for i in range(8):\n",
    "    img = final_fakes[i].cpu().permute(1, 2, 0).numpy()\n",
    "    img = (img + 1) / 2\n",
    "    axes[1, i].imshow(np.clip(img, 0, 1))\n",
    "    axes[1, i].set_title(f'{final_scores[i].item():.3f}', fontsize=10, color='blue')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Ğ¡Ğ³ĞµĞ½ĞµÑ€.', fontsize=12, rotation=0, labelpad=50)\n",
    "\n",
    "plt.suptitle('Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ: Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ vs Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ (Ñ‡Ğ¸ÑĞ»Ğ° = TIGAS score)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ… TIGAS:\")\n",
    "print(f\"   Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ: {real_tigas.mean().item():.4f}\")\n",
    "print(f\"   Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ: {final_scores.mean().item():.4f}\")\n",
    "print(f\"   Ğ Ğ°Ğ·Ğ½Ğ¸Ñ†Ğ°: {real_tigas.mean().item() - final_scores.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada90e0",
   "metadata": {},
   "source": [
    "## ğŸ“ 7. Ğ’Ñ‹Ğ²Ğ¾Ğ´Ñ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af898b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                        Ğ˜Ğ¢ĞĞ“Ğ˜ Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ˜ĞœĞ•ĞĞ¢Ğ                        â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                  â•‘\n",
    "â•‘  âœ… TIGAS ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ°ĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ â•‘\n",
    "â•‘                                                                  â•‘\n",
    "â•‘  âœ… TIGAS Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ğº Ğ´Ğ¸Ñ„Ñ„ĞµÑ€ĞµĞ½Ñ†Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¹ loss           â•‘\n",
    "â•‘     Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹                            â•‘\n",
    "â•‘                                                                  â•‘\n",
    "â•‘  âœ… TIGAS score ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚               â•‘\n",
    "â•‘     Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ GAN                                      â•‘\n",
    "â•‘                                                                  â•‘\n",
    "â•‘  ğŸ’¡ Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ:                                        â•‘\n",
    "â•‘     â€¢ ĞÑ†ĞµĞ½ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹                       â•‘\n",
    "â•‘     â€¢ Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ loss Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸           â•‘\n",
    "â•‘     â€¢ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°                       â•‘\n",
    "â•‘     â€¢ Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ deepfakes Ğ¸ AI-ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹        â•‘\n",
    "â•‘                                                                  â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸:\")\n",
    "print(f\"   ĞĞ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ TIGAS(fake): {history['tigas_score_fake'][0]:.4f}\")\n",
    "print(f\"   Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ TIGAS(fake): {history['tigas_score_fake'][-1]:.4f}\")\n",
    "print(f\"   Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ: +{history['tigas_score_fake'][-1] - history['tigas_score_fake'][0]:.4f}\")\n",
    "print(f\"\\n   TIGAS(real) baseline: {history['tigas_score_real'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825d49f",
   "metadata": {},
   "source": [
    "## ğŸ”— Ğ¡ÑÑ‹Ğ»ĞºĞ¸\n",
    "\n",
    "- **GitHub**: [H1merka/TIGAS](https://github.com/H1merka/TIGAS)\n",
    "- **HuggingFace**: [H1merka/TIGAS](https://huggingface.co/H1merka/TIGAS)\n",
    "- **PyPI**: `pip install tigas-metric`\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚\n",
    "from tigas import TIGAS\n",
    "\n",
    "tigas = TIGAS(auto_download=True)\n",
    "score = tigas('your_image.jpg')  # 1.0 = real, 0.0 = fake\n",
    "\n",
    "# ĞšĞ°Ğº loss Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°\n",
    "loss = 1.0 - tigas(generated_images).mean()\n",
    "loss.backward()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
